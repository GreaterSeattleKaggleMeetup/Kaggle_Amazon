{
  "metadata": {
    "kernelspec": {
      "name": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.5.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "## Classifying the Amazon Rainforest\n\nWelcome back to another satellite imagery competition - these seem to be in fashion lately :) This time, unlike other recent satellite imagery competitions, we have to add tags to each image (which are segments of a larger image of the Amazon Rainforest). However, since each image can have multiple labels, that makes this a **multi-label** classification challenge as opposed to standard multi-class problem.\n\n**And as always, if this helped you, some upvotes would be very much appreciated - that's where I get my motivation! :D**\n\nTime to get straight into the data:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport gc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\npal = sns.color_palette()\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nprint('# File sizes')\nfor f in os.listdir('../input'):\n    if not os.path.isdir('../input/' + f):\n        print(f.ljust(30) + str(round(os.path.getsize('../input/' + f) / 1000000, 2)) + 'MB')\n    else:\n        sizes = [os.path.getsize('../input/'+f+'/'+x)/1000000 for x in os.listdir('../input/' + f)]\n        print(f.ljust(30) + str(round(sum(sizes), 2)) + 'MB' + ' ({} files)'.format(len(sizes)))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Wow, so Kaggle Kernels has the full data! (Thanks Kaggle Team! :))\n\nLooks like we have 40k images for training, and 40k images for testing.\nThe jpegs are on average **15KB**, and the tifs are on average **538KB**. The JPEGs seem a little on the small side, but TIFFs look like they will retain most of the quality.\n\nBefore we open up the images, let's take a look at the `train.csv`.\n## Training Data",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df_train = pd.read_csv('../input/train.csv')\ndf_train.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Okay, so our training metadata is super basic. It looks like we are just given names and the corresponding tags. Let's parse them and do some analysis",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "labels = df_train['tags'].apply(lambda x: x.split(' '))",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "So it looks like we are not given much metadata, only the filenames and the corresponding tags. Let's parse these tags so that we can analyze them further.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "labels = df_train['tags'].apply(lambda x: x.split(' '))\nfrom collections import Counter, defaultdict\ncounts = defaultdict(int)\nfor l in labels:\n    for l2 in l:\n        counts[l2] += 1\n\ndata=[go.Bar(x=list(counts.keys()), y=list(counts.values()))]\nlayout=dict(height=800, width=800, title='Distribution of training labels')\nfig=dict(data=data, layout=layout)\npy.iplot(data, filename='train-label-dist')",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Co-occurence Matrix\ncom = np.zeros([len(counts)]*2)\nfor i, l in enumerate(list(counts.keys())):\n    for i2, l2 in enumerate(list(counts.keys())):\n        c = 0\n        cy = 0\n        for row in labels.values:\n            if l in row:\n                c += 1\n                if l2 in row: cy += 1\n        com[i, i2] = cy / c\n\ndata=[go.Heatmap(z=com, x=list(counts.keys()), y=list(counts.keys()))]\nlayout=go.Layout(height=800, width=800, title='Co-occurence matrix of training labels')\nfig=dict(data=data, layout=layout)\npy.iplot(data, filename='train-com')",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "It's worth noting that this co-occurence matrix shows **what percentage of the X label also has the Y label** - I think this shows more information than the standard symmetrical matrix.\n\nWe can see that the label \"primary\" has the highest proportion of labels.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Images\nNow, what you all came for. Let's load some of the images, and their corresponding labels.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import cv2\n\nnew_style = {'grid': False}\nplt.rc('axes', **new_style)\n_, ax = plt.subplots(3, 3, sharex='col', sharey='row', figsize=(20, 20))\ni = 0\nfor f, l in df_train[:9].values:\n    img = cv2.imread('../input/train-jpg/{}.jpg'.format(f))\n    ax[i // 3, i % 3].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    ax[i // 3, i % 3].set_title('{} - {}'.format(f, l))\n    #ax[i // 4, i % 4].show()\n    i += 1\n    \nplt.show()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    }
  ]
}